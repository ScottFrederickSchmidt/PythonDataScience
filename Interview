Introduction:
First off, hello Kevin! Glad we get to chat again since being ISU MBA graduates. 
Accepting the data science position means more to me than programming in Python/SQL. 
On my first-year anniversary as a Python data scientist, I plan to donate 3% of my first year's salary to an ISU Python student as a scholarship.
I hope this gives inspiration for every ISU student to graduate because I too am also an ISU graduate. 


1. How does this position fit with the career path you envision for yourself?
I want to improve my Python skills where I can become as strong as a Python Data Scientist as Arafath Hossain, a current Data Scientist at ISU.
I have not met him in person but have briefly talked with him over LinkedIn. 
His recent Pell grant project on GitHub he voluntarily made is one of the most amazing things I have seen in the past few months, and I want to be like him.
I will not be leaving the data science position in the next six years so I can achieve my ten-year pension. 
This makes me the best long-term investment for the position.
Illinois State University is home to me as a former, current, and future student.
I hope my following answers represent Illinois State University well as the #1 university in the nation! 



2. Data extrapolation and analysis are critical to accurate models being developed.  Please describe an example of data extract and analysis that you have completed.
At Illinois State University, I invented a Python data science pandas dataFrame automation program that 
compares thousands of data transactions to database records which detects unbalanced accounts, new transactions, and human error: 
https://github.com/ScottFrederickSchmidt/AccountingAutomation


This was a very important task because it involves accounting. If the program is not 100% accurate, one could
get involved in an audit that could cost the company thousands of dollars and a bad reputation. In accounting, one must be exact.
There are no guesses. Accuracy, attention to detail and perfection is of highest importance.




3. Please describe the experience you have creating predictive models.

At Douglas Capital Management, I used portfolio123.com database with hundreds of finance formulas to predict future returns. For instance,
OperCashFlTTM - CapExTTM + IntExpTTM*(1-TaxRate%TTMInd/100) would be inserted into a database with an optimization process to see how this one 
formula can affect future returns. More important formulas such as annual growth rate would have a higher significance for returns.
We also had to account for missing data. On occasion, missing data was completely deleted. But the majority of the time,
missing data was filled in using a estimate by a regression line. Basic MATLAB functions would be used to help find the statistic relevance of each formula. 
In 2019, our returns were in the top ten.


During my MBA program as an ISU graduate assistant, I generated a 95% r-squared using data analytics (depends on adjustment to overfitting). 
This identified the best candidates that would most likely successfully graduate at ISU. This was the final MBA capstone course, MQM497. 
In conclusion, Pell Grants and amount of initiated contacts are the two biggest factors in whether a student enrolled at the university or not. 
These two factors alone can make a fairly good prediction on whether a student enrolls at the university or not. 
In conclusion, neural networks show that undecided majors, Pell Grant, distance from ISU, # of initiated events, family income median, total consumer expenditures, 
high school low income percentage, and high school GPA are the major factors in whether a student enrolls at Illinois State University or not. 
The test confirms that ACT, GPA, major, Pell Grant, and # of initiated events make a significant difference in students enrolling at Illinois State University.  


At Clark Street Capital, I used machine learning and correlations to predict loan risk. 
My "Amazon" website has a basic recommendation system that would predict what purchases the customer might want to buy next.




4. In terms of SQL syntax or query structure, what are some things you focus on when writing a query to ensure it functions as efficiently as possible?


Coding efficiency, queries, and data manipulation is my strength as I have over one thousand hours in data manipulation which can be viewed on both GitHub and YouTube.
One must not just code, but code in the correct order and logic. My data manipulation skills can be viewed here:
https://github.com/ScottFrederickSchmidt/Project-Euler-Python
https://github.com/ScottFrederickSchmidt/LeetCode


Memory is an important issue of the life of a programmer. This is because Excel has a max of around two million rows 
while Python can have a max out on memory with very large, complex dataFrame. However, having rows at this magnitude does not happen often. 
Therefore, Python cam be used as primary data manipulation language using pandas.
This is what Python was specifically designed for and why it is now one of the most used languages in the world.
In a rare event there was data with more than ten million rows, I would be able to manipulate the data with SQL but it would
take me much longer than with Python. Challenging SQL analytics was done in my Udemy course which can be found below:
https://github.com/ScottFrederickSchmidt/Complete-SQL-Bootcamp-and-SQL-DataAnalytics-Course


On my "Amazon" site, I built an entire SQL database that was on the backend. It is connected on the frontend using PHP. 
The basic SQL terminology were all used for this project (i.e. select, insert, update, delete). 
In addition, it has a basic SQL search and recommendation section. All these SQL queries happened with high performance speed.
See code for reference: https://github.com/ScottFrederickSchmidt/Amazon-like-site




5. Part of the Data Scientist role will be to provide visualizations that will be able to explain the analysis that you have performed. 
What tools have you used to create data visualizations?  
I have mostly used Tableau and Excel for visualizations. In a recent data science
poll on LinkedIn I saw Excel was ranked as being "highly underrated" for data science. Because I have a web development background,
I could also display graphs on the Illinois State University website if needed with JavaScript such
as https://www.chartjs.org/docs.




6. Please describe a presentation that you have completed to present the results of a predictive model you developed.	
At Clark Street Capital, I had to help package and sell at $42 million dollar non-performing commercial real estate loan bundled together 
as a mortgage-back security through a major United States bank. Based upon our predictive analysis, the goal was to sell the loan
around eighty cents on the dollar. I had to help present this package over phone to around over a hundred banking clients across
the United States.


At Illinois State University, I invented a Python data science pandas dataFrame automation program that 
compares thousands of data transactions to database records which detects unbalanced accounts, new transactions, and human error: 
https://github.com/ScottFrederickSchmidt/AccountingAutomation


I have presented this project to several programming professors and directors because I have wanted to try to implement my 
program on a more frequent and global basis. I truly believe my program can save ISU over a hundred thousand dollars a year if correctly implemented. 
It will also make the life of an accountant more enjoyable. Presenting programming code is more of a challenge than I originally thought because 
I have concluded that data manipulation and programming are almost two completely different specialized subjects. 


Predictive Python projects can be found on the following link:
https://github.com/ScottFrederickSchmidt/PredictivePythonModeling


7. Have you ever had to “sell” an idea to your co-workers, supervisor or customers? How did you do it?  
Great question! I think my data science accounting automation software I have developed would save Illinois State University, 
if implemented correctly, well over a hundred thousand dollars a year. But I have not had the confidence to "sell" my idea.

A prepared prototype using fake data was built before hand so I had confidence the program would work.
When I did invent my automation program, I did request permission to use the data first.
I also made sure that no confidential information would accidently be leaked.
The idea was successfully implemented with highest honors. 


8. During analysis, how do you treat missing values?
The simple, easy way to treat missing values is to simply delete any data row that has a missing value using a simple Python script such as
df.dropna().  However, this can give less data points to make accurate predictions.

Most commonly, is one can use predictive scores to get an "average" of what the missing data probably is using a 
simple regression line. This is the best common practice but also takes more time.

A bad choice would be to fill the missing data with a 0 because this would easily distort the data.

Lastly, if there is not a lot of data points with lots of missing data, one should consider not using that data at all. 
For instance, when analyzing microcap stocks at Douglas Capital Management 
using portfolio123.com, there were times certain financial formulas were completely removed from the optimization
process due to lack of accurate data.


9. What are the tools you have most commonly used to complete predictive analysis?  Which one is your favorite?   
Python Pandas dataFrame is by far my favorite tool. This is what I used to automate the accounting analytics predictions at Illinois State University,
financial automation at Douglas Capital Management, and some predictive analytics at Clark Street Capital. 
This is what was taught in my Data Science Bootcamp on Udemy and by my data science mentor, Sukamar Lagapati.


Salesforce has done a fantastic job with their implementation of Tableau. Tableau gives a data scientist
an easy way to explain data to an individual who may not have a statistics or coding background. 
In fact, Tableau makes it easy for even developers to understand data and make analytical decisions.
